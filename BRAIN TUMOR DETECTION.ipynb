{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5962731,"sourceType":"datasetVersion","datasetId":3419493}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# First, install the library needed to split the folders\n!pip install split-folders\n\nimport splitfolders\nimport os\n\n# --- THIS IS THE CORRECTED CODE ---\n\n# 1. Define the path to your original dataset\n# This path is based on the output of your !ls command\ninput_folder = \"/kaggle/input/imagesoasis/Data\"\n\n# 2. Define the path where the new split dataset will be created\noutput_folder = \"/kaggle/working/split_data\"\n\n# 3. Split the data into a training set (75%) and a testing set (25%).75\nsplitfolders.ratio(input_folder, output=output_folder, seed=42, ratio=(.75, .25))\n\nprint(\"Dataset successfully split into train and test sets.\")\nprint(f\"Split data is now located in: {output_folder}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T16:09:59.979799Z","iopub.execute_input":"2025-10-26T16:09:59.980071Z","iopub.status.idle":"2025-10-26T16:34:12.422988Z","shell.execute_reply.started":"2025-10-26T16:09:59.980054Z","shell.execute_reply":"2025-10-26T16:34:12.422254Z"}},"outputs":[{"name":"stdout","text":"Collecting split-folders\n  Downloading split_folders-0.5.1-py3-none-any.whl.metadata (6.2 kB)\nDownloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\nInstalling collected packages: split-folders\nSuccessfully installed split-folders-0.5.1\n","output_type":"stream"},{"name":"stderr","text":"Copying files: 86437 files [24:06, 59.77 files/s] ","output_type":"stream"},{"name":"stdout","text":"Dataset successfully split into train and test sets.\nSplit data is now located in: /kaggle/working/split_data\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"!ls /kaggle/input/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T16:34:12.424451Z","iopub.execute_input":"2025-10-26T16:34:12.424657Z","iopub.status.idle":"2025-10-26T16:34:12.564632Z","shell.execute_reply.started":"2025-10-26T16:34:12.424641Z","shell.execute_reply":"2025-10-26T16:34:12.563931Z"}},"outputs":[{"name":"stdout","text":"imagesoasis\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"test_dir = os.path.join(output_folder, \"test\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T16:34:12.565603Z","iopub.execute_input":"2025-10-26T16:34:12.565873Z","iopub.status.idle":"2025-10-26T16:34:12.569772Z","shell.execute_reply.started":"2025-10-26T16:34:12.565850Z","shell.execute_reply":"2025-10-26T16:34:12.569237Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport os\n\n# --- FIX 1: Use the correct path from your first cell ---\noutput_folder = \"/kaggle/working/split_data\"\n# --------------------------------------------------------\n\n# Define the directories\ntrain_dir = os.path.join(output_folder, \"train\")\n\n# --- FIX 2: Your 'splitfolders' created 'test', not 'val' ---\ntest_dir = os.path.join(output_folder, \"test\") \n# ----------------------------------------------------------\n\nBATCH_SIZE = 32\n\n# Create a generator for training and validation\n# 15% of this data will be used for validation\ntrain_val_datagen = ImageDataGenerator(\n    rescale=1./255,\n    validation_split=0.15,  # Reserve 15% of the training data for validation\n    \n    # --- Added Augmentations ---\n    rotation_range=15,      \n    width_shift_range=0.1,  \n    height_shift_range=0.1, \n    shear_range=0.1,        \n    zoom_range=0.1,         \n    horizontal_flip=True,   \n    fill_mode='nearest'     \n    # ---------------------------\n)\n\n# A separate generator for the test set (only rescaling)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\n# Create the train generator from the 'training' subset\ntrain_generator = train_val_datagen.flow_from_directory(\n    train_dir,\n    target_size=(224, 224),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    subset='training'  # Specify this is the training set\n)\n\n# Create the validation generator from the 'validation' subset\nval_generator = train_val_datagen.flow_from_directory(\n    train_dir, # Note: It uses the same directory\n    target_size=(224, 224),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    subset='validation' # Specify this is the validation set\n)\n\n# Create the test generator from the corrected path ('test_dir')\ntest_generator = test_datagen.flow_from_directory(\n    test_dir, # <-- This now correctly points to your 'test' folder\n    target_size=(224, 224),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=False\n)\n\nprint(\"Data generators created successfully!\")\n# You can also check the number of images found\nprint(f\"Found {train_generator.samples} images for training.\")\nprint(f\"Found {val_generator.samples} images for validation.\")\nprint(f\"Found {test_generator.samples} images for testing.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T16:34:12.571394Z","iopub.execute_input":"2025-10-26T16:34:12.572013Z","iopub.status.idle":"2025-10-26T16:34:13.308674Z","shell.execute_reply.started":"2025-10-26T16:34:12.571990Z","shell.execute_reply":"2025-10-26T16:34:13.307397Z"}},"outputs":[{"name":"stdout","text":"Found 55105 images belonging to 4 classes.\nFound 9721 images belonging to 4 classes.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3133504236.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;31m# Create the test generator from the corrected path ('test_dir')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m test_generator = test_datagen.flow_from_directory(\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mtest_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# <-- This now correctly points to your 'test' folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \u001b[0mkeep_aspect_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m     ):\n\u001b[0;32m-> 1138\u001b[0;31m         return DirectoryIterator(\n\u001b[0m\u001b[1;32m   1139\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/working/split_data/test'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/working/split_data/test'","output_type":"error"}],"execution_count":9},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Model\n# Make sure to import the Dropout layer\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Concatenate, Flatten, Dense, Dropout\n\n# Input Layer\ninputs = Input(shape=(224, 224, 3))\n\n# ======================\n# First Block\n# ======================\nx = layers.Conv2D(128, (3, 3), activation='relu', padding=\"same\")(inputs)\nx = layers.Conv2D(128, (3, 3), activation='relu', padding=\"same\")(x)\nx = layers.MaxPooling2D((2, 2))(x)\n\n# ======================\n# Second Block\n# ======================\nx = layers.Conv2D(256, (3, 3), activation='relu', padding=\"same\")(x)\nx = layers.Conv2D(256, (3, 3), activation='relu', padding=\"same\")(x)\nx = layers.MaxPooling2D((2, 2))(x)\n\n# ======================\n# Parallel Branches\n# ======================\n\n# Branch 1\nbranch1 = layers.Conv2D(64, (3, 3), activation='relu', padding=\"same\")(x)\nbranch1 = layers.Conv2D(64, (3, 3), activation='relu', padding=\"same\")(branch1)\n\n# Branch 2\nbranch2 = layers.Conv2D(64, (3, 3), activation='relu', padding=\"same\")(x)\nbranch2 = layers.Conv2D(64, (3, 3), activation='relu', padding=\"same\")(branch2)\n\n# Concatenate feature maps\nconcat = layers.Concatenate()([branch1, branch2])\n\n# ======================\n# Fully Connected Layers\n# ======================\nflatten = layers.Flatten()(concat)\ndense1 = layers.Dense(64, activation='relu')(flatten)\n\n# --- NEW DROPOUT LAYER ADDED HERE ---\n# Add a Dropout layer after the 64-neuron dense layer.\n# A rate of 0.5 is a common starting point.\ndropout = Dropout(0.5)(dense1)\n\n# --- THIS IS THE CORRECTED LINE ---\n# The final output layer now has 4 units to match your 4 classes\noutputs = layers.Dense(4, activation='softmax')(dropout)\n\n# Create the model\nmodel = Model(inputs=inputs, outputs=outputs)\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T16:34:13.309293Z","iopub.status.idle":"2025-10-26T16:34:13.309600Z","shell.execute_reply.started":"2025-10-26T16:34:13.309419Z","shell.execute_reply":"2025-10-26T16:34:13.309436Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(train_generator.class_indices)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T16:34:13.310532Z","iopub.status.idle":"2025-10-26T16:34:13.310830Z","shell.execute_reply.started":"2025-10-26T16:34:13.310658Z","shell.execute_reply":"2025-10-26T16:34:13.310673Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 6. Create and Compile the Model\nmodel = Model(inputs=inputs, outputs=outputs)\nmodel.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# 7. Print the Model Summary\nprint(\"Model Summary:\")\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T16:34:13.312248Z","iopub.status.idle":"2025-10-26T16:34:13.312530Z","shell.execute_reply.started":"2025-10-26T16:34:13.312382Z","shell.execute_reply":"2025-10-26T16:34:13.312399Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = model.fit(\n    train_generator,\n    epochs= 30,\n    validation_data=val_generator,\n    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n    validation_steps=val_generator.samples // BATCH_SIZE\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T16:34:13.313282Z","iopub.status.idle":"2025-10-26T16:34:13.313689Z","shell.execute_reply.started":"2025-10-26T16:34:13.313496Z","shell.execute_reply":"2025-10-26T16:34:13.313515Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results = model.evaluate(test_generator,steps=len(test_generator), verbose=1)\nprint(\"Test Accuracy:\", results[1])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T16:34:13.314997Z","iopub.status.idle":"2025-10-26T16:34:13.315304Z","shell.execute_reply.started":"2025-10-26T16:34:13.315124Z","shell.execute_reply":"2025-10-26T16:34:13.315138Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\n# 2. Predictions\nY_pred = model.predict(test_generator, verbose=1)\ny_pred = np.argmax(Y_pred, axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T16:34:13.316799Z","iopub.status.idle":"2025-10-26T16:34:13.317068Z","shell.execute_reply.started":"2025-10-26T16:34:13.316945Z","shell.execute_reply":"2025-10-26T16:34:13.316959Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ======================\n# 🔹 Save Weights\n# ======================\nmodel.save(\"/kaggle/working/brain_tumor.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T16:34:13.318796Z","iopub.status.idle":"2025-10-26T16:34:13.319094Z","shell.execute_reply.started":"2025-10-26T16:34:13.318987Z","shell.execute_reply":"2025-10-26T16:34:13.318998Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\n\n# 1. Get the true labels from the generator\ntrue_labels = test_generator.classes\n\n# 2. Make predictions (if you haven't already)\n# This returns probabilities\nprobabilities = model.predict(test_generator)\n\n# 3. Convert probabilities to predicted class labels\ny_pred = np.argmax(probabilities, axis=1)\n\n# 4. Create and plot the confusion matrix\ncm = confusion_matrix(true_labels, y_pred)\n\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n            xticklabels=test_generator.class_indices.keys(),\n            yticklabels=test_generator.class_indices.keys())\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T16:34:13.319904Z","iopub.status.idle":"2025-10-26T16:34:13.320240Z","shell.execute_reply.started":"2025-10-26T16:34:13.320060Z","shell.execute_reply":"2025-10-26T16:34:13.320074Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(\"\\n Classification Report:\\n\")\nprint(classification_report(test_generator.classes, y_pred,\n                            target_names=list(test_generator.class_indices.keys())))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T16:34:13.321427Z","iopub.status.idle":"2025-10-26T16:34:13.321721Z","shell.execute_reply.started":"2025-10-26T16:34:13.321574Z","shell.execute_reply":"2025-10-26T16:34:13.321587Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 5. Per-class accuracy\ncm_diag = np.diag(cm) / np.sum(cm, axis=1)\nfor idx, cls in enumerate(test_generator.class_indices.keys()):\n    print(f\"Class {cls}: {cm_diag[idx]*100:.2f}% accuracy\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T16:34:13.323737Z","iopub.status.idle":"2025-10-26T16:34:13.323943Z","shell.execute_reply.started":"2025-10-26T16:34:13.323848Z","shell.execute_reply":"2025-10-26T16:34:13.323856Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Get the data from the history object\naccuracy = history.history['accuracy']\nval_accuracy = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(accuracy))\n\n# Plot Training and Validation Accuracy\nplt.plot(epochs, accuracy, 'r', label='Training accuracy')\nplt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\nplt.title('Training and Validation Accuracy')\nplt.legend()\n\nplt.figure()\n\n# Plot Training and Validation Loss\nplt.plot(epochs, loss, 'r', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and Validation Loss')\nplt.legend()\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T16:34:13.324561Z","iopub.status.idle":"2025-10-26T16:34:13.324875Z","shell.execute_reply.started":"2025-10-26T16:34:13.324711Z","shell.execute_reply":"2025-10-26T16:34:13.324724Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}